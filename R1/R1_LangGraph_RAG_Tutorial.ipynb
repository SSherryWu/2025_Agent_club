{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8820c727ef074689afa5fa4e002caa70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9238d70f50fe42ffb302b5b6d10a9643",
              "IPY_MODEL_2611c18e21e74279b07a1e742a2d4edd",
              "IPY_MODEL_d57cd89cb96e4c82bb66b5a2576862a6"
            ],
            "layout": "IPY_MODEL_d3761b2cf15d4de2be0d1ca52df76f7f"
          }
        },
        "9238d70f50fe42ffb302b5b6d10a9643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f6ff73cc1ef4366ab4c7dc8058b850c",
            "placeholder": "​",
            "style": "IPY_MODEL_0d705d77f6bd434db25b14b41c3d3ceb",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2611c18e21e74279b07a1e742a2d4edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bbbc460377f43d3ab6a09c288105b93",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a159d3b6aba46739a571217e2e59924",
            "value": 4
          }
        },
        "d57cd89cb96e4c82bb66b5a2576862a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d551b6ac31d04e7ab877cdbd14c200cb",
            "placeholder": "​",
            "style": "IPY_MODEL_601537321d7649c4b827ff25ac1082f4",
            "value": " 4/4 [01:16&lt;00:00, 15.51s/it]"
          }
        },
        "d3761b2cf15d4de2be0d1ca52df76f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f6ff73cc1ef4366ab4c7dc8058b850c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d705d77f6bd434db25b14b41c3d3ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bbbc460377f43d3ab6a09c288105b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a159d3b6aba46739a571217e2e59924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d551b6ac31d04e7ab877cdbd14c200cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "601537321d7649c4b827ff25ac1082f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UgOU80G6LSnE"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langgraph transformers bitsandbytes langchain-huggingface langchain-community chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangGraph"
      ],
      "metadata": {
        "id": "dpqj6aWx_noI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangGraph 是建立在 LangChain 基礎上的進階框架，專門設計來支援 有狀態 (stateful)、多輪互動的 LLM 應用。\n",
        "\n",
        "它最適合開發需要「多步推理」、「分支決策」、「循環執行」的場景，例如智慧助理、複雜的問答流程、知識檢索 (RAG) 系統等等。\n",
        "\n",
        "這個函式庫的核心思想是：以「有向圖 (Directed Graph)」的方式來設計 LLM 應用流程，每個節點 (Node) 是一個執行單位，各節點之間以邊 (Edge) 連結，定義資料如何流動。\n",
        "\n",
        "Graph 是由幾個主要組件組成的：\n",
        "\n",
        "1. 節點 (Nodes)：每個節點代表一個行動，像是呼叫 LLM、檢索資料、計算條件判斷等。\n",
        "\n",
        "2. 邊 (Edges)：節點與節點之間的連接，可以設定固定流程 (Next Step) 或依條件 (Condition) 分流。\n",
        "\n",
        "3. 狀態 (State)：在整個執行過程中，會保存並更新的狀態資訊，讓多輪互動成為可能。\n",
        "\n",
        "LangGraph 支援與 LangChain 模組緊密整合，例如：\n",
        "\n",
        "1. Prompt templates：在節點中組合提示內容。\n",
        "\n",
        "2. LLMs：調用 GPT-4o、Claude、Llama3 等模型進行回應。\n",
        "\n",
        "3. Tools & Agents：結合網路搜尋、資料庫查詢、計算器等外部工具。\n",
        "\n",
        "4. Memory：在流程中持續更新記憶體，實現更自然的多輪對話。"
      ],
      "metadata": {
        "id": "MCpc4SaqBnp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 以 LangGraph 做一個簡單的 ChatBot"
      ],
      "metadata": {
        "id": "7nqT7qK8F864"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 模型載入"
      ],
      "metadata": {
        "id": "fN9v_901JXSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "因示範用模型載入較大，所以這邊做了量化處理 (適用於低記憶體的 GPU，例如 Colab T4)。\n",
        "\n",
        "有野心的人可以召喚自己的魔法小卡來更換成更強大的閉源模型，或跟我一樣當免費仔使用其他開源模型。"
      ],
      "metadata": {
        "id": "SWA7I9M-CLjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "\n",
        "# 使用 4-bit 量化模型\n",
        "model_id = \"MediaTek-Research/Breeze-7B-Instruct-v1_0\"\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    llm_int8_threshold=6.0,\n",
        ")\n",
        "\n",
        "# 載入 tokenizer 與 4-bit 模型\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quant_config,\n",
        "    trust_remote_code=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8820c727ef074689afa5fa4e002caa70",
            "9238d70f50fe42ffb302b5b6d10a9643",
            "2611c18e21e74279b07a1e742a2d4edd",
            "d57cd89cb96e4c82bb66b5a2576862a6",
            "d3761b2cf15d4de2be0d1ca52df76f7f",
            "7f6ff73cc1ef4366ab4c7dc8058b850c",
            "0d705d77f6bd434db25b14b41c3d3ceb",
            "2bbbc460377f43d3ab6a09c288105b93",
            "1a159d3b6aba46739a571217e2e59924",
            "d551b6ac31d04e7ab877cdbd14c200cb",
            "601537321d7649c4b827ff25ac1082f4"
          ]
        },
        "id": "u1XXfKgOPBph",
        "outputId": "01380d11-67dc-42eb-c33b-ad9b4cb7bcc0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8820c727ef074689afa5fa4e002caa70"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 建立 text generation pipeline\n",
        "generator = pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=True,\n",
        "    temperature=0.4,\n",
        "    return_full_text=False # 僅返回生成的回應內容\n",
        ")\n",
        "\n",
        "# 包裝成 LangChain 的 llm 物件\n",
        "llm = HuggingFacePipeline(pipeline=generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM-tGIHEVpC_",
        "outputId": "f4ec1c6b-9aec-4ac8-97af-cd90df722277"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 定義狀態（State）"
      ],
      "metadata": {
        "id": "QGRsNkWfKyUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "核心概念\n",
        "1. 每個節點（Node）在執行前，會接收一個 State。\n",
        "\n",
        "2. 每個節點執行後，必須回傳更新後的 State。\n",
        "\n",
        "3. State 通常用 TypedDict 或 BaseModel 定義，且每個欄位應明確標注資料型別（如 str、list、dict）。\n",
        "\n",
        "> ※ 這裡只示範 TypedDict，對 BaseModel 有興趣的同學可以自行研究。\n",
        "\n",
        "常見 State 欄位類型\n",
        "1. query: str → 問題\n",
        "2. messages: Annotated[list, add_messages] → 聊天歷史訊息\n",
        "  \n",
        "  (messages 這個欄位是個列表，而且每次節點傳回新的 messages 時，不是覆蓋整個列表，而是append到原來的列表)\n",
        "3. docs: List[Document] → 找到的知識庫文件\n",
        "\n",
        "  (docs 這個欄位是個列表，裡面放的是 Document 類型的資料)\n",
        "4. error: Optional[str] → 記錄錯誤訊息（如果中途出錯）"
      ],
      "metadata": {
        "id": "nSpCQ8gvN3Lv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "↓下方定義 State 結構，只有一個欄位 messages，用來儲存對話訊息的歷史紀錄（人類訊息 + AI 回應）。"
      ],
      "metadata": {
        "id": "Df0osDsHKabL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "# 定義 LangGraph 的 State 結構\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]"
      ],
      "metadata": {
        "id": "s58YnIFM6cbQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 定義節點（Node）"
      ],
      "metadata": {
        "id": "UuhGKXXHQWb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "每一個 Node 負責處理一個任務。\n",
        "\n",
        "這裡的 chatbot 節點，會接收使用者訊息，整理成 Breeze 格式的 prompt，丟給模型產生回應，然後把回應加回到對話紀錄中。"
      ],
      "metadata": {
        "id": "lndNZatRQoT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "\n",
        "# 定義節點 (Node)\n",
        "def chatbot(state: State):\n",
        "    messages = state[\"messages\"]\n",
        "    if messages[-1].type != \"human\":\n",
        "        raise ValueError(\"最後一個訊息必須是 human（user）\")\n",
        "\n",
        "    # 第一次對話時，要求使用繁體中文(可有可無)\n",
        "    if len(messages) == 1:\n",
        "        user_message = messages[-1]\n",
        "        zh_hint = \"請使用繁體中文。\\n\"\n",
        "        patched_user_message = HumanMessage(content=zh_hint + user_message.content)\n",
        "        patched_messages = messages[:-1] + [patched_user_message]\n",
        "    else:\n",
        "        patched_messages = messages\n",
        "\n",
        "    chat_list = []\n",
        "    for m in patched_messages:\n",
        "        if isinstance(m, HumanMessage):\n",
        "            chat_list.append({\"role\": \"user\", \"content\": m.content})\n",
        "        elif isinstance(m, AIMessage):\n",
        "            chat_list.append({\"role\": \"assistant\", \"content\": m.content})\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    chat_list.append({\"role\": \"assistant\", \"content\": \"\"})\n",
        "\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        chat_list,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "    )\n",
        "\n",
        "    result = llm.invoke(prompt)\n",
        "\n",
        "    return {\"messages\": messages + [AIMessage(content=result)]}"
      ],
      "metadata": {
        "id": "4FApvmOO6fDU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 建立 LangGraph 流程圖（StateGraph）"
      ],
      "metadata": {
        "id": "499ivDniRFVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用 StateGraph 來把 chatbot 功能組成一個圖。\n",
        "\n",
        "這裡的流程非常單純，只有一個節點（chatbot），進入和結束的地方都設定在這個節點，並利用邊(edge)來連接。"
      ],
      "metadata": {
        "id": "m7Y8qpPDRISa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# 建立 LangGraph\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "# 編譯 Graph\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "LamKYINR6g4J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 視覺化"
      ],
      "metadata": {
        "id": "5jNsbfkUSUSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "KM4_GmMeWKKq",
        "outputId": "6439ec97-7aea-465d-ac01-0b026dbcdb5f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. chatbot 結果"
      ],
      "metadata": {
        "id": "kwUTMo9LSXkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "這裡的 LangGraph chatbot 有「短期記憶」，但沒有「長期記憶」。\n",
        "\n",
        "messages 變數會持續累積每一輪對話，把過去對話都「重新包成 prompt」送進模型。模型每次回答前，都能「看到目前所有訊息」。\n",
        "\n",
        "後續的課程中將會講解並演示 Agent 的長期記憶 。"
      ],
      "metadata": {
        "id": "jiL7ARLDmjPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "messages = []\n",
        "\n",
        "print(\"開始對話吧（輸入 q 結束）\")\n",
        "while True:\n",
        "    user_input = input(\"使用者: \")\n",
        "    if user_input.strip().lower() in [\"q\", \"quit\", \"exit\"]:\n",
        "        print(\"掰啦！\")\n",
        "        break\n",
        "\n",
        "    messages.append(HumanMessage(content=user_input))\n",
        "\n",
        "    result = graph.invoke({\"messages\": messages})\n",
        "    response = result[\"messages\"][-1].content\n",
        "\n",
        "    print(\"AI 助理:\", response.strip())\n",
        "    messages.append(AIMessage(content=response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW0ow87u-9Dh",
        "outputId": "68a170ae-ae29-4d02-9bda-68b4bc423d6f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "開始對話吧（輸入 q 結束）\n",
            "使用者: q\n",
            "掰啦！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "tqeIx7mD6FUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 以 LangGraph 實現帶條件判斷的 RAG 流程"
      ],
      "metadata": {
        "id": "OCGdg2rLTN85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "docs_text = \"\"\"\n",
        "火影代數\t姓名\t師傅\t徒弟\n",
        "初代\t千手柱間\t無明確記載\t猿飛日斬、水戶門炎、轉寢小春\n",
        "二代\t千手扉間\t千手柱間（兄長）\t猿飛日斬、志村團藏、宇智波鏡等\n",
        "三代\t猿飛日斬\t千手柱間、千手扉間\t自來也、大蛇丸、千手綱手（傳說三忍）\n",
        "四代\t波風湊\t自來也\t旗木卡卡西、宇智波帶土、野原琳\n",
        "五代\t千手綱手\t猿飛日斬\t春野櫻、志乃等（主要為春野櫻）\n",
        "六代\t旗木卡卡西\t波風湊\t漩渦鳴人、宇智波佐助、春野櫻（第七班）\n",
        "七代\t漩渦鳴人\t自來也、旗木卡卡西\t木葉丸等（主要為木葉丸）\n",
        "\"\"\"\n",
        "\n",
        "docs = [Document(page_content=txt.strip()) for txt in docs_text.strip().split(\"\\n\\n\")]\n",
        "\n",
        "# chromadb 預設使用的大型語言模型為 \"all-MiniLM-L6-v2\"，由於該大型語言模型不支持中文，所以將模型替換為 \"infgrad/stella-base-zh-v3-1792d\"，並對 embedding 進行量化\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"infgrad/stella-base-zh-v3-1792d\",\n",
        "    encode_kwargs={\"normalize_embeddings\": True}\n",
        ")\n",
        "\n",
        "persist_path = \"document_store\"\n",
        "collection_name = \"naruto_collection\"\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=embedding_model,\n",
        "    persist_directory=persist_path,\n",
        "    collection_name=collection_name\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ds8YDd2OPe4",
        "outputId": "1e7f8b94-771c-4511-e77a-a8396b248ee6",
        "collapsed": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at infgrad/stella-base-zh-v3-1792d and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 模型載入"
      ],
      "metadata": {
        "id": "ZvNW71MfVQq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用的模型與 chatbot 教學同一顆"
      ],
      "metadata": {
        "id": "wFnvRVQpU7W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=True,\n",
        "    temperature=0.4,\n",
        "    return_full_text=False # 僅返回生成的回應內容\n",
        ")"
      ],
      "metadata": {
        "id": "uD7juOvTU6to",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff2b8087-6062-4620-8a5e-7c62ffeffc8d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 定義狀態（State）"
      ],
      "metadata": {
        "id": "myq54ykXoW0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "這裡定義的 RAGState，包含了查詢文字（query）、檢索到的文件（docs）、以及最後生成的回答（answer）。"
      ],
      "metadata": {
        "id": "BRCuRU3svPHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict, List\n",
        "\n",
        "# 定義 LangGraph 的 State 結構\n",
        "class RAGState(TypedDict):\n",
        "    query: str\n",
        "    docs: List[Document]\n",
        "    answer: str"
      ],
      "metadata": {
        "id": "pphh39DEoYNM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 定義節點（Node）"
      ],
      "metadata": {
        "id": "wpylZY_mo7QF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_node(state: RAGState) -> RAGState:\n",
        "    query = state[\"query\"]\n",
        "    # similarity_search 距離越小越相似\n",
        "    docs = vectorstore.similarity_search(query, k=3)\n",
        "    return {\"query\": query, \"docs\": docs, \"answer\": \"\"}\n",
        "\n",
        "def generate_node(state: RAGState) -> RAGState:\n",
        "    query, docs = state[\"query\"], state[\"docs\"]\n",
        "    context = \"\\n\".join([d.page_content for d in docs])\n",
        "    prompt = (\n",
        "        f\"你是一個知識型助手，請根據以下內容回答問題：\\n\\n\"\n",
        "        f\"內容：{context}\\n\\n\"\n",
        "        f\"問題：{query}\\n\\n回答：\"\n",
        "    )\n",
        "    output = generator(prompt, max_new_tokens=200)[0][\"generated_text\"]\n",
        "    return {\"query\": query, \"docs\": docs, \"answer\": output}\n",
        "\n",
        "def direct_generate_node(state: RAGState) -> RAGState:\n",
        "    query = state[\"query\"]\n",
        "    prompt = f\"請回答以下問題：{query}\\n\\n回答：\"\n",
        "    output = generator(prompt, max_new_tokens=200)[0][\"generated_text\"]\n",
        "    return {\"query\": query, \"docs\": [], \"answer\": output}\n",
        "\n",
        "# 定義 Route Node（決定走哪條路）\n",
        "def route_by_query(state):\n",
        "    # keywords = [\"火影\", \"忍者\", \"歷代\"]\n",
        "    query = state[\"query\"]\n",
        "    top = vectorstore.similarity_search_with_score(query, k=1)\n",
        "    _, distance = top[0]\n",
        "    cosine = 1 - distance\n",
        "    # choice = \"naruto\" if any(word in query for word in keywords) else \"general\"\n",
        "    choice = \"naruto\" if cosine > 0.5 else \"general\"\n",
        "    # print(distance)\n",
        "    print(f\"跑到 → {choice}\")\n",
        "    return choice"
      ],
      "metadata": {
        "id": "Knra8WF3M0r9"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 建立 LangGraph 流程圖（StateGraph）"
      ],
      "metadata": {
        "id": "zTk67tnLpM_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在 LangGraph / LangChain 裡，RunnableLambda 就是用來把一個普通的 Python 函式（function）包裝成一個「Runnable」物件。\n",
        "\n",
        "Runnable 是 LangChain 裡的一個「標準介面」（Protocol Interface），代表「這個東西可以 .invoke()、可以被執行」。\n",
        "\n",
        "> ※ 換句話說：RunnableLambda 讓普通函式能接到 LangGraph 的 Node 上運行。"
      ],
      "metadata": {
        "id": "G30TGyOVr-LV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "為什麼第一個例子 chatbot 不需要使用 RunnableLambda ?\n",
        "\n",
        "- 如果只是單線到底（直直連接），不管有幾個節點，都不用自己包 RunnableLambda。\n",
        "\n",
        "- 只要涉及「判斷分流」、「根據條件走不同路線」，就一定要自己把判斷的 function 包成 RunnableLambda"
      ],
      "metadata": {
        "id": "3mLuCxndtTxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# 建立 LangGraph 流程圖\n",
        "graph_builder = StateGraph(RAGState)\n",
        "\n",
        "graph_builder.set_entry_point(\"condition\")\n",
        "graph_builder.add_node(\"condition\", RunnableLambda(lambda x: x))  # 進來就分流，不改變內容\n",
        "graph_builder.add_node(\"retriever\", RunnableLambda(retrieve_node))\n",
        "graph_builder.add_node(\"generator\", RunnableLambda(generate_node))\n",
        "graph_builder.add_node(\"direct_generator\", RunnableLambda(direct_generate_node))\n",
        "\n",
        "# 設定條件分流\n",
        "graph_builder.add_conditional_edges(\n",
        "    source=\"condition\",\n",
        "    path=RunnableLambda(route_by_query),\n",
        "    path_map={\n",
        "        \"naruto\": \"retriever\",\n",
        "        \"general\": \"direct_generator\",\n",
        "    }\n",
        ")\n",
        "\n",
        "# 接下來的正常連接\n",
        "graph_builder.add_edge(\"retriever\", \"generator\")\n",
        "graph_builder.add_edge(\"generator\", END)\n",
        "graph_builder.add_edge(\"direct_generator\", END)\n",
        "\n",
        "# 編譯 Graph\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "UGMAM1ZypQzE"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 視覺化"
      ],
      "metadata": {
        "id": "8I5pHFropsIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "id": "2IxEyiWaNvd-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. RAG 結果"
      ],
      "metadata": {
        "id": "BLWrWd1gVd6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"開始對話吧（輸入 q 結束）\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"使用者: \")\n",
        "    if user_input.strip().lower() in [\"q\", \"quit\", \"exit\"]:\n",
        "        print(\"掰啦！\")\n",
        "        break\n",
        "\n",
        "    # 設定初始 State\n",
        "    init_state: RAGState = {\n",
        "        \"query\": user_input,\n",
        "        \"docs\": [],\n",
        "        \"answer\": \"\"\n",
        "    }\n",
        "    # 呼叫 LangGraph\n",
        "    result = graph.invoke(init_state)\n",
        "    raw_output = result[\"answer\"]\n",
        "\n",
        "    answer_text = raw_output.split(\"回答：\")[-1].strip()\n",
        "    print(\"回答：\", answer_text)\n",
        "    print(\"===\" * 20, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeEqEVw2C88W",
        "outputId": "b3fecac1-6ade-4a28-a66d-8f62cf99f9ee"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "開始對話吧（輸入 q 結束）\n",
            "使用者: 初代火影是誰\n",
            "跑到 → naruto\n",
            "回答： 初代火影是千手柱間。\n",
            "============================================================ \n",
            "\n",
            "使用者: 第三代火影是誰\n",
            "跑到 → general\n",
            "回答： 第三代火影是宇智波佐助。\n",
            "============================================================ \n",
            "\n",
            "使用者: 那猿飛日斬是第幾代火影\n",
            "跑到 → naruto\n",
            "回答： 猿飛日斬是第三代火影。\n",
            "============================================================ \n",
            "\n",
            "使用者: 第三代火影是誰\n",
            "跑到 → general\n",
            "回答： 第三代火影是宇智波斑。宇智波斑是宇智波家族的後裔，也是宇智波家族的最後一員。他在火影的任期中，努力地在世界各地建立起新的火影村，以保障火影的安全。宇智波斑在火影的任期中，也成功地阻止了許多危險的勢力，例如：天狗、大蛇丸等。宇智波斑的能力非常高，他可以利用自己的血輪眼來預測未來，並且可以控制自己的血液，從而增強自身的能力。宇智波斑在火影的任期中，為火影村的發展做出了巨大的貢獻，被後人尊稱為「火影之祖」。\n",
            "============================================================ \n",
            "\n",
            "使用者: q\n",
            "掰啦！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2hSUZlYsh83x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}